{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade network analysis\n",
    "**Brian Dew (brianwdew@gmail.com)**\n",
    "\n",
    "`05_em-dat.ipynb`\n",
    "\n",
    "Generates a csv file with the year of and country affected by large natural disasters. \n",
    "\n",
    "Required file:\n",
    "\n",
    "* em-dat.csv - Raw natural disaster data from [EM-DAT: The International Disaster Database](http://www.emdat.be/) Advanced Search.\n",
    "\n",
    "---\n",
    "\n",
    "METODO: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd                                         # pandas dataframes used for convenience\n",
    "import os                                                   # change current directory in next line\n",
    "os.chdir('C:/Working/trade_network/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read csv downloaded from em-dat. I used the advanced search on all countries years 2009-2015 and all natural disasters. I then grouped only by year and country. The resultant csv file has a column for the total deaths and a column labeled occurence which contains the number of disasters. I'm interested in really large disasters, which must be large enough, or few enough, to have a major economic impact through decreased exports. I therefore have a cutoff below for the average number of deaths per occurance. I find that large countries have many disasters and therefore a cutoff, of say 100, in absolute terms will add the US, India, and China to the list for each year. There are a few years where these countries had major natural disasters that I seek to include in this measure. The cutoff can be adjusted to check for robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('em-dat.csv', header=0, index_col='year')\n",
    "em_countries = {}\n",
    "for y in range(2008,2015):\n",
    "    em_countries[y] = df[ (df['Total deaths'] / df['occurrence'] ) > 39.9].loc[y]   # CUTOFF\n",
    "    em_countries[y]['y'] = y                                            \n",
    "emergency_countries = pd.concat(em_countries, axis=0).reset_index()[['y','iso']]\n",
    "emergency_countries['s'] = 1     \n",
    "# Create a dictionary of iso2 country codes, Namibia is interpreted as NaN without the keep_default_na\n",
    "iso2 = pd.read_csv('country_code_baci07.csv', index_col='iso3', keep_default_na=False, na_values=[''])['iso2'].to_dict()\n",
    "emergency_countries['iso'] = emergency_countries['iso'].apply(lambda x: iso2.get(x,x)) # replace country names\n",
    "# to merge and create dummy\n",
    "emergency_countries.to_csv('emergency_countries.csv', index=None)    # save as csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
