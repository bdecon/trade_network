{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade Network Analysis\n",
    "`08_imports_decomp.ipynb`\n",
    "\n",
    "Requires:\n",
    "\n",
    "1. `fat_tailed_prod.csv` created by `03_deg_dist.ipynb`\n",
    "2. `emergency_countries` created by `05_em-dat.ipynb`\n",
    "3. Cleaned trade data for each year created by `02_clean.ipynb`\n",
    "\n",
    "Produces a csv file with the USD value (in thousands) of each countries imports for each year decomposed into four categories.\n",
    "\n",
    "* cs: value of imports of products with fat-tailed distribution of exporter sizes imported from countries with a natural disaster in the next year. The c stands for 'central players' and the s stands for 'supply shock'.\n",
    "* ns: value of imports of products with more normal distribution of exporter sizes imported from countries with a natural disaster in the next year.\n",
    "* cn: value of imports of products with fat-tailed distribution of exporter sizes imported from countries with no major natural disaster in the next year.\n",
    "* nn: value of imports of products with more normal distribution of exporter sizes imported from countries with no major natural disaster in the next year.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "METODO:\n",
    "1. Annotate \n",
    "2. Add text above with formulas\n",
    "3. Calculate percentage of total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd                                         # pandas dataframes used for convenience\n",
    "import os                                                   # change current directory in next line\n",
    "os.chdir('C:/Working/trade_network/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load distribution and natural disaster data\n",
    "\n",
    "Load distribution and natural disaster dummy variable datasets from csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fat_tailed_prod = pd.read_csv('fat_tailed_prod.csv', index_col='year')\n",
    "emer_c = pd.read_csv('emergency_countries.csv', index_col='y')\n",
    "emer_c = emer_c.rename(columns={'iso': 'i'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decompose imports for each country and year\n",
    "\n",
    "The dummy variable sets from above are joined to the cleaned trade data. The value of exports is then multiplied by the dummy data so bilateral trade values are each put into one the four buckets described in the header. The results are summed by country and saved as an annual csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for y in range(2008,2015):         # start year & end year + 1 \n",
    "    ftp = fat_tailed_prod.loc[y].reset_index()[['hs6','c']].set_index('hs6')\n",
    "    ec = emer_c.loc[y].reset_index()[['i','s']].set_index('i')\n",
    "    base_file = pd.read_csv('clean/baci07_'+str(y)+'_clean.csv')[['hs6','i','j','v']]\n",
    "    df = base_file.join(ec, on='i').join(ftp, on='hs6').fillna(value=0)\n",
    "    df['cs'] = (df['v'] * df['c'] * df['s'])                    \n",
    "    df['ns'] = (df['v'] * (1 - df['c']) * df['s'])\n",
    "    df['cn'] = (df['v'] * (1 - df['s']) * df['c'])\n",
    "    df['nn'] = (df['v'] * (1 - df['s']) * (1 - df['c']))\n",
    "    df.groupby(['j']).sum()[['cs','ns','cn','nn']].to_csv('summary/imports_decomp_'+str(y)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine to one file\n",
    "\n",
    "This just puts together the annual csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = {}\n",
    "for y in range(2008,2015):         # start year & end year + 1 '\n",
    "    df[y] = pd.read_csv('summary/imports_decomp_'+str(y)+'.csv', index_col='j')\n",
    "pd.concat(df, axis=0).to_csv('imports_decomp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
